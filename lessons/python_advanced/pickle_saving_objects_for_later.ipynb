{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.7.4 (default, Aug 13 2019, 15:17:50) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python Version:\", sys.version, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle: Saving Objects for Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in data science, we'll create some model or some version of our data and want to use it later. We have many options - we can save the coefficients, or save the data to csv, or...\n",
    "\n",
    "Actually, we don't have that many options. \n",
    "\n",
    "One way to overcome that is to save the python object to a file as a serialized object. That means we convert the entire object to a bunch of bytes, save those bytes into a file, and then have the ability to unpack those bytes back into their original format later. \n",
    "\n",
    "This is done by a module called `pickle`. Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "lots_of_noise = {\n",
    "    'CA': [random.randint(0,65) for _ in range(100)],\n",
    "    'IL': [random.randint(0,65) for _ in range(50)],\n",
    "    'NY': [random.randint(0,65) for _ in range(90)],\n",
    "    'WA': [random.randint(0,65) for _ in range(33)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CA': [55, 40, 44, 50, 46, 60, 5, 61, 59, 38, 7, 39, 38, 35, 17, 47, 57, 5, 52, 60, 25, 36, 15, 62, 52, 10, 22, 4, 28, 65, 63, 47, 50, 21, 32, 9, 56, 2, 43, 31, 65, 33, 64, 39, 42, 26, 6, 5, 33, 29, 46, 8, 22, 57, 21, 17, 62, 7, 56, 40, 51, 1, 48, 23, 3, 38, 60, 13, 25, 33, 34, 56, 57, 6, 12, 64, 41, 63, 18, 60, 51, 63, 10, 32, 51, 43, 52, 11, 24, 59, 52, 44, 57, 8, 40, 2, 58, 18, 24, 58], 'IL': [40, 49, 24, 46, 7, 58, 56, 32, 6, 63, 38, 41, 52, 50, 33, 20, 55, 36, 58, 50, 12, 49, 43, 49, 17, 12, 44, 46, 56, 5, 14, 58, 64, 14, 65, 59, 24, 49, 38, 12, 55, 40, 12, 39, 20, 46, 30, 61, 31, 32], 'NY': [41, 0, 37, 31, 38, 1, 0, 11, 15, 60, 19, 22, 48, 20, 29, 53, 20, 53, 63, 34, 25, 10, 52, 51, 23, 37, 53, 52, 5, 18, 2, 15, 7, 37, 29, 27, 13, 1, 10, 27, 47, 33, 34, 22, 59, 31, 27, 44, 58, 62, 53, 15, 26, 8, 25, 32, 53, 44, 58, 13, 27, 26, 6, 13, 43, 30, 10, 27, 61, 30, 1, 9, 16, 17, 65, 26, 39, 26, 14, 1, 1, 23, 7, 38, 51, 4, 30, 40, 8, 36], 'WA': [32, 25, 10, 1, 45, 33, 3, 9, 24, 29, 36, 59, 14, 47, 37, 49, 3, 15, 15, 10, 44, 3, 12, 39, 22, 35, 10, 59, 20, 27, 38, 39, 62]}\n"
     ]
    }
   ],
   "source": [
    "print(lots_of_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable        Type      Data/Info\n",
      "-----------------------------------\n",
      "lots_of_noise   dict      n=4\n",
      "pickle          module    <module 'pickle' from '/U<...>lib/python3.7/pickle.py'>\n",
      "random          module    <module 'random' from '/U<...>lib/python3.7/random.py'>\n",
      "sys             module    <module 'sys' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in this `whos` command that the object `lots_of_noise` exists and is a `dict` with 4 keys. Nice. Now let's look at our file system and verify that there isn't a file called `noise.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced_python_datatypes.ipynb       my_dataframe.pickle\r\n",
      "complexity.md                         noise.pickle\r\n",
      "deep_and_shallow_copy.ipynb           pickle_saving_objects_for_later.ipynb\r\n",
      "\u001b[34mdeep_copy_demo\u001b[m\u001b[m                        readme.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we're ready to create a file and write the bytes to it. To do this with `pickle`, we use python's read-write streamer `open` and create a writable-binary (`wb`) file. We'll then use `pickle.dump` to put an object into that file as a string of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noise.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lots_of_noise, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced_python_datatypes.ipynb       my_dataframe.pickle\r\n",
      "complexity.md                         noise.pickle\r\n",
      "deep_and_shallow_copy.ipynb           pickle_saving_objects_for_later.ipynb\r\n",
      "\u001b[34mdeep_copy_demo\u001b[m\u001b[m                        readme.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete `lots_of_noise` and prove to ourselves it doesn't exist in Python's memory anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lots_of_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lots_of_noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-69f22b4d5ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlots_of_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lots_of_noise' is not defined"
     ]
    }
   ],
   "source": [
    "print(lots_of_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lovely. It's dead forever. Or is it?\n",
    "\n",
    "Let's open that `noise.pickle` file with read-binary (`rb`) mode. Then we'll ask pickle to retrieve the file with `pickle.load` and store it back in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noise.pickle','rb') as read_file:\n",
    "    new_noise = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CA': [55, 40, 44, 50, 46, 60, 5, 61, 59, 38, 7, 39, 38, 35, 17, 47, 57, 5, 52, 60, 25, 36, 15, 62, 52, 10, 22, 4, 28, 65, 63, 47, 50, 21, 32, 9, 56, 2, 43, 31, 65, 33, 64, 39, 42, 26, 6, 5, 33, 29, 46, 8, 22, 57, 21, 17, 62, 7, 56, 40, 51, 1, 48, 23, 3, 38, 60, 13, 25, 33, 34, 56, 57, 6, 12, 64, 41, 63, 18, 60, 51, 63, 10, 32, 51, 43, 52, 11, 24, 59, 52, 44, 57, 8, 40, 2, 58, 18, 24, 58], 'IL': [40, 49, 24, 46, 7, 58, 56, 32, 6, 63, 38, 41, 52, 50, 33, 20, 55, 36, 58, 50, 12, 49, 43, 49, 17, 12, 44, 46, 56, 5, 14, 58, 64, 14, 65, 59, 24, 49, 38, 12, 55, 40, 12, 39, 20, 46, 30, 61, 31, 32], 'NY': [41, 0, 37, 31, 38, 1, 0, 11, 15, 60, 19, 22, 48, 20, 29, 53, 20, 53, 63, 34, 25, 10, 52, 51, 23, 37, 53, 52, 5, 18, 2, 15, 7, 37, 29, 27, 13, 1, 10, 27, 47, 33, 34, 22, 59, 31, 27, 44, 58, 62, 53, 15, 26, 8, 25, 32, 53, 44, 58, 13, 27, 26, 6, 13, 43, 30, 10, 27, 61, 30, 1, 9, 16, 17, 65, 26, 39, 26, 14, 1, 1, 23, 7, 38, 51, 4, 30, 40, 8, 36], 'WA': [32, 25, 10, 1, 45, 33, 3, 9, 24, 29, 36, 59, 14, 47, 37, 49, 3, 15, 15, 10, 44, 3, 12, 39, 22, 35, 10, 59, 20, 27, 38, 39, 62]}\n"
     ]
    }
   ],
   "source": [
    "print(new_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable    Type              Data/Info\n",
      "---------------------------------------\n",
      "new_noise   dict              n=4\n",
      "pickle      module            <module 'pickle' from '/U<...>lib/python3.7/pickle.py'>\n",
      "random      module            <module 'random' from '/U<...>lib/python3.7/random.py'>\n",
      "read_file   BufferedReader    <_io.BufferedReader name='noise.pickle'>\n",
      "sys         module            <module 'sys' (built-in)>\n",
      "to_write    BufferedWriter    <_io.BufferedWriter name='noise.pickle'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random noise lives! We retrieved the entire structure from file. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, but I don't use dictionaries... I use pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yay</th>\n",
       "      <th>specific</th>\n",
       "      <th>column</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-5.512436</td>\n",
       "      <td>-2.055927</td>\n",
       "      <td>-1.328419</td>\n",
       "      <td>2.703297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-9.595825</td>\n",
       "      <td>1.476920</td>\n",
       "      <td>7.924709</td>\n",
       "      <td>-1.016286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.142081</td>\n",
       "      <td>-9.576473</td>\n",
       "      <td>-7.069010</td>\n",
       "      <td>-7.449866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.631534</td>\n",
       "      <td>-6.996479</td>\n",
       "      <td>2.582262</td>\n",
       "      <td>6.292607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.399294</td>\n",
       "      <td>3.811161</td>\n",
       "      <td>9.469380</td>\n",
       "      <td>-9.734305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Yay  specific    column     names\n",
       "0 -5.512436 -2.055927 -1.328419  2.703297\n",
       "1 -9.595825  1.476920  7.924709 -1.016286\n",
       "2  9.142081 -9.576473 -7.069010 -7.449866\n",
       "3  5.631534 -6.996479  2.582262  6.292607\n",
       "4  1.399294  3.811161  9.469380 -9.734305"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.uniform(-10,10, size=(100,4)), columns=['Yay','specific','column','names'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_dataframe.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3975f6306adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "del df\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_dataframe.pickle','rb') as read_file:\n",
    "    new_df = pickle.load(read_file)\n",
    "    \n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle is a great tool. One recommended way of using it is to make it an end point of every step in your process. Example:\n",
    "\n",
    "* I got my data! Nice. Pickle it and stop your \"getting the data\" notebook.\n",
    "* Load your data from pickle. Clean it. Save your clean data to a new pickle.\n",
    "* Load your cleaned_data pickle. Do analysis and visualize it.\n",
    "\n",
    "This can provide natural \"pick-up-where-I-left-off-but-before-I-broke-my-data\" points. It's a great way to control the flow of your data.\n",
    "\n",
    "#### Resources\n",
    "\n",
    "https://docs.python.org/3.7/library/pickle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
